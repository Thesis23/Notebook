{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de459f2b",
   "metadata": {},
   "source": [
    "# Beer Image Processing\n",
    "#### Using cv2 and tensorflow (DNN and LSTM) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bde4b9",
   "metadata": {},
   "source": [
    "## IMPORTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6cc7bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9422afb",
   "metadata": {},
   "source": [
    "## PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e540a99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_beer_color(image):\n",
    "    # Resize the image\n",
    "    cropped_image = image[94:118, 114:138] # 24 x 24\n",
    "    \n",
    "    # Calculate the average color (BGR format)\n",
    "    avg_color = cv2.mean(cropped_image)[:3]\n",
    "    \n",
    "    avg_color_rgb = avg_color[::-1]\n",
    "\n",
    "    return avg_color_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d76065b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sediment_image(image):\n",
    "    # Resize the image\n",
    "    image = image[212:252, 114:158] # 48 x 40\n",
    "    \n",
    "    # Convert the image depth to CV_32F if necessary\n",
    "    if image.dtype != np.float32:\n",
    "        image = image.astype(np.float32)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ece843f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_foam_image(image):\n",
    "    # Resize the image\n",
    "    image = image[14:96, 96:112] # 16 x 72\n",
    "    \n",
    "    # Convert the image depth to CV_32F if necessary\n",
    "    if image.dtype != np.float32:\n",
    "        image = image.astype(np.float32)\n",
    "        \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6755617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_grayscale(image):\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    return gray_image\n",
    "\n",
    "def increase_brightness_contrast(image, alpha=1.0, beta=0):\n",
    "    # Adjust the brightness and contrast of the image\n",
    "    adjusted_image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "    return adjusted_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b77aa6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    # normalization for visualisation\n",
    "    image_data_type = image.dtype\n",
    "\n",
    "    if image_data_type == np.float32 or image_data_type == np.float64:\n",
    "        # Normalize the float image to the range [0, 1]\n",
    "        normalized_image = (image - np.min(image)) / (np.max(image) - np.min(image))\n",
    "    else:\n",
    "        # Convert the image to float and normalize it to the range [0, 1]\n",
    "        normalized_image = image.astype(np.float32) / 255.0\n",
    "\n",
    "    return normalized_image\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8da31e3f",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2180019137.py, line 44)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn [11], line 44\u001b[1;36m\u001b[0m\n\u001b[1;33m    if min_height is not None and max_height is not None:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "def get_height(image, check):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    image = to_grayscale(image)\n",
    "\n",
    "    # Increase the brightness and contrast of the image\n",
    "    image = increase_brightness_contrast(image, alpha=0.68, beta=14)\n",
    "\n",
    "    # Convert the grayscale image back to RGB\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    # Convert the image to HSV\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    # Define the color range for the foam and sediment\n",
    "    lower_range = np.array([0, 0, 100])  # Lower range for foam and sediment\n",
    "    upper_range = np.array([180, 240, 160])  # Upper range for foam and sediment (V <= 240)\n",
    "\n",
    "    # Create a mask using the color range\n",
    "    mask = cv2.inRange(hsv, lower_range, upper_range)\n",
    "    \n",
    "    # Apply the mask to the original image\n",
    "    masked_image = cv2.bitwise_and(image, image, mask=mask)\n",
    "    \n",
    "    # Initialize min and max height variables\n",
    "    min_height = None\n",
    "    max_height = None\n",
    "\n",
    "    # Iterate through the mask to find the highest and lowest points with continuous color\n",
    "    for y in range(mask.shape[0]):\n",
    "        # Check if the current row contains continuous color\n",
    "        if np.all(mask[y, :] > 0):\n",
    "            if min_height is None:\n",
    "                min_height = y\n",
    "            max_height = y\n",
    "            \n",
    "    cv2.imshow(\"Original Image\", image)\n",
    "    cv2.imshow(\"HSV Image\", hsv)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Calculate the height\n",
    "    if min_height is not None and max_height is not None:\n",
    "        height = max_height - min_height + 1\n",
    "    else:\n",
    "        height = 0\n",
    "\n",
    "    return height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b51c970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "# Get all .jpg image paths in a folder\n",
    "folder_path = \"../PythonArduino/PythonCode/images/\"\n",
    "image_paths = glob.glob(os.path.join(folder_path, \"*.jpg\"))\n",
    "\n",
    "# Sort image paths based on their names (assuming they are named with ascending timestamps)\n",
    "image_paths.sort()\n",
    "\n",
    "# Set corresponding timestamps for each image\n",
    "timestamps = list(range(len(image_paths)))  # Using indices as timestamps, you can replace them with actual timestamps if available\n",
    "\n",
    "# fig, axs = plt.subplots(2)\n",
    "# fig.suptitle('Images')\n",
    "\n",
    "data = []\n",
    "for image_path, timestamp in zip(image_paths, timestamps):\n",
    "      \n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Resize the image\n",
    "    image = image[224:480, 244:500] # 256 x 256\n",
    "    \n",
    "    # sediment\n",
    "    sediment_image = get_sediment_image(image)\n",
    "    sediment_image = normalize(sediment_image)\n",
    "#     axs[0].imshow(cv2.cvtColor(sediment_image, cv2.COLOR_BGR2RGB))\n",
    "    sediment_height= get_height(sediment_image, 1)\n",
    "    \n",
    "    # foam\n",
    "    foam_image = get_foam_image(image)\n",
    "    foam_image = normalize(foam_image)\n",
    "#     axs[1].imshow(cv2.cvtColor(foam_image, cv2.COLOR_BGR2RGB))\n",
    "    foam_height= get_height(foam_image, 0)\n",
    "    \n",
    "    # beer color\n",
    "    beer_color = get_beer_color(image)\n",
    "    \n",
    "    data.append([timestamp, foam_height, beer_color, sediment_height])\n",
    "\n",
    "# Convert data to a DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"timestamp\", \"foam_height\", \"beer_color\", \"sediment_height\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4259c4bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=69f7515c-d622-4a2d-92c6-3ca1e2de4035 style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands?.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('69f7515c-d622-4a2d-92c6-3ca1e2de4035').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>foam_height</th>\n",
       "      <th>beer_color</th>\n",
       "      <th>sediment_height</th>\n",
       "      <th>fermentation_progress</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(112.10069444444444, 53.34548611111111, 42.83680555555555)</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>(112.015625, 53.390625, 42.89236111111111)</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>(106.14583333333333, 49.248263888888886, 40.43402777777778)</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(110.09201388888889, 52.32118055555555, 42.869791666666664)</td>\n",
       "      <td>0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>(96.9079861111111, 45.20833333333333, 41.93402777777778)</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "   timestamp  foam_height                                         beer_color  \\\n",
       "0          0            0  (112.10069444444444, 53.34548611111111, 42.836...   \n",
       "1          1            0         (112.015625, 53.390625, 42.89236111111111)   \n",
       "2          2            0  (106.14583333333333, 49.248263888888886, 40.43...   \n",
       "3          3            0  (110.09201388888889, 52.32118055555555, 42.869...   \n",
       "4          4            0  (96.9079861111111, 45.20833333333333, 41.93402...   \n",
       "\n",
       "   sediment_height  fermentation_progress  \n",
       "0                0                    0.0  \n",
       "1                0                   25.0  \n",
       "2                0                   50.0  \n",
       "3                0                   75.0  \n",
       "4                0                  100.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Add fermentation progress to the DataFrame\n",
    "fermentation_progress = [] # List of fermentation progress values corresponding to each image\n",
    "for i in range(len(image_paths)):\n",
    "    fermentation_progress.append(round((100 / (len(image_paths) - 1)) * i, 2))\n",
    "\n",
    "df[\"fermentation_progress\"] = fermentation_progress\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4199e84",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'tuple'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [10], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Normalize the input features using MinMaxScaler\u001b[39;00m\n\u001b[0;32m      6\u001b[0m scaler \u001b[38;5;241m=\u001b[39m MinMaxScaler()\n\u001b[1;32m----> 7\u001b[0m X \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(df[input_columns])\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Prepare the output values\u001b[39;00m\n\u001b[0;32m     10\u001b[0m y \u001b[38;5;241m=\u001b[39m df[output_column]\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[1;32m~\\.conda\\envs\\ML-ENV\\lib\\site-packages\\sklearn\\utils\\_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 142\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    144\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    147\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    148\u001b[0m         )\n",
      "File \u001b[1;32m~\\.conda\\envs\\ML-ENV\\lib\\site-packages\\sklearn\\base.py:859\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    858\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\.conda\\envs\\ML-ENV\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:427\u001b[0m, in \u001b[0;36mMinMaxScaler.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\ML-ENV\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:466\u001b[0m, in \u001b[0;36mMinMaxScaler.partial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    461\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMinMaxScaler does not support sparse input. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    462\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConsider using MaxAbsScaler instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    463\u001b[0m     )\n\u001b[0;32m    465\u001b[0m first_pass \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 466\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_pass\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    471\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    473\u001b[0m data_min \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanmin(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    474\u001b[0m data_max \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanmax(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\ML-ENV\\lib\\site-packages\\sklearn\\base.py:546\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    545\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 546\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    547\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    548\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32m~\\.conda\\envs\\ML-ENV\\lib\\site-packages\\sklearn\\utils\\validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    877\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    878\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 879\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    882\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    883\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\ML-ENV\\lib\\site-packages\\sklearn\\utils\\_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    182\u001b[0m     xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(array)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.array_api\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\.conda\\envs\\ML-ENV\\lib\\site-packages\\pandas\\core\\generic.py:2070\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2069\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m-> 2070\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "# Define input and output columns\n",
    "input_columns = [\"foam_height\", \"beer_color\", \"sediment_height\"]\n",
    "output_column = \"fermentation_progress\"\n",
    "\n",
    "# Normalize the input features using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(df[input_columns])\n",
    "\n",
    "# Prepare the output values\n",
    "y = df[output_column].values\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "# Reshape the input data for LSTM (samples, timesteps, features)\n",
    "timesteps = 1\n",
    "X_train = X_train.reshape(X_train.shape[0], timesteps, X_train.shape[1])\n",
    "X_test = X_test.reshape(X_test.shape[0], timesteps, X_test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6493c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(timesteps, X_train.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(32, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.001), loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcffefbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the testing dataset\n",
    "test_loss, test_mae = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"Test loss: {test_loss}, Test MAE: {test_mae}\")\n",
    "\n",
    "# Visualize the training and validation loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9f4f2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfb9240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733f145d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
